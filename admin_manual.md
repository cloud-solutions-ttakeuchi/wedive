# 管理画面マニュアル (Admin Manual)

本ドキュメントでは、場所データ（Region / Zone / Area / Point）の管理を行う「管理画面 (Admin Area Cleansing Page)」の機能について説明します。

**アクセスURL**: `/admin/cleansing`

---

## 1. データ閲覧・検索機能

### 階層タブ切り替え
画面上部のタブで、表示・操作するデータの階層を切り替えることができます。
- **Region (都道府県/国)**: 最上位の区分（例: 沖縄本島、石垣島など）
- **Zone (エリア)**: Regionの下位区分（例: 恩納村、川平・石崎など）
- **Area (地区)**: Zoneの下位区分（例: 万座、マンタスクランブル周辺など）
- **Point (ダイビングポイント)**: 実際のダイビングスポット

### 複数条件フィルタリング (Multi-Select Filter)
リスト上部のドロップダウンを使用して、表示するデータを絞り込むことができます。
- **Region Filter**: 選択したRegion（複数可）に含まれるデータのみを表示します。
- **Zone Filter**: 選択したZone（複数可）に含まれるデータのみを表示します。
- **Area Filter** (Pointタブのみ): 選択したArea（複数可）等のポイントを表示します。
※ フィルタは連動しており、Regionを選択すると、その配下のZoneのみが選択肢として表示されます。

### 全データ表示
ポイントが登録されていない（0件の）Region/Zone/Areaもリストに表示されるため、未使用データの確認や整理が可能です。

---

## 2. マスタデータ管理機能 (CRUD)

### 新規作成 (Create)
Region, Zone, Area タブにある「+ Create New ...」ボタンから、新しい項目を追加できます。
- **Name**: 名称を入力
- **Description**: 説明文を入力
- **Parent**: 所属する親階層を選択（例: Areaを作成する場合は親Zoneを選択）

### 編集・移動 (Edit & Move)
各行の右側にある「Edit」ボタン（ペンアイコン）から、既存データの編集が可能です。
- **名称・説明の変更**: 誤字脱字の修正など。
- **親階層の変更 (移動)**: ドロップダウンで親を変更することで、データを別の場所に移動できます（例: Areaを別のZoneへ移動）。
    - **Pointの移動**: 間違ったAreaに登録してしまったPointも、こちらから正しいAreaに移動可能です。
        - **ゾーン選択で絞り込み**: エリアの選択肢が現在のゾーンに限定されて表示されます。別のゾーンへ移動したい場合は、下部の「Filter by Zone」を変更してください。
  - ※移動しても、その配下にあるPointデータは自動的に追従しますが、データ整合性のために「DB同期」が必要になる場合があります。

---

## 3. 一括操作機能 (Bulk Actions)

### 複数選択 (Checkboxes)
- 各行の左側にあるチェックボックスで、操作したいデータを選択します。
- ヘッダーのチェックボックスをクリックすると、表示されている全データを選択/解除できます。

### 一括削除 (Bulk Delete)
データを選択すると、画面下部にアクションバーが表示されます。「Bulk Delete」ボタンを押すと、選択したデータを一括で削除できます。
- **Pointの削除**: 関連するユーザーログ等は削除されませんが、ポイント情報は物理削除されます。
- **Region/Zone/Areaの削除**: その項目自体が削除されます。紐付いていたPointのフィールド（area名など）は空欄等の状態になります。

---

## 4. データ保守・連携機能

### 削除時のデータ整合性 (Deletion Behavior)
本管理画面での削除操作には、対象データによって挙動が異なります（安全設計）。

#### A. Region / Zone / Area の削除 (一括・個別共通)
これらを削除しても、配下の **Point (ダイビングポイント) 自体は削除されません**。
- **挙動**: 対象のマスタデータが削除され、紐付いていた Point 側の当該フィールド（region/zone/area名）は「未設定 (空文字)」の状態になります。また、`areaId` 等の内部リンクもクリアされます。
- **影響**: ポイントに紐付いている「生物情報」や「ユーザーのお気に入り」は**全て維持されます**。

#### B. Point の削除
Point を削除した場合は、データの不整合（ゴミデータ）が残らないように**カスケード削除**が行われます。
- **挙動**: Point ドキュメントが物理削除されます。
- **影響**:
    1. **生物紐付け (PointCreatures)**: そのポイントに関連する生物出現情報は全て削除されます。
    2. **お気に入り (Bookmarks)**: ユーザーがお気に入り登録していた場合、そのリストから削除されます。
    3. **Wantedリスト**: ユーザーが見たい生物リスト（場所指定）からも削除されます。
- **注意**: 削除されたポイントは復元できません。

### Export JSON (バックアップ)
画面上部のExportボタンから、以下のデータをJSON形式でダウンロードできます。
- **Export Locations**: 場所データ (`locations_seed.json` 形式)
- **Export Creatures**: 生物図鑑データ (`creatures_real.json` 形式)
- **Export Relations**: ポイント-生物紐付けデータ (`point_creatures_seed.json` 形式)

**用途**: データのバックアップ、または開発環境のシードファイルの更新に使用します。

### DB同期 (DB Sync)
「DB同期」ボタンをクリックすると、表示上のデータとFirestoreの最新状態を同期し、キャッシュ等の不整合を解消します。

### 重複修復 (Repair Duplicates)
「重複修復」ボタンは、システム上の重複IDや不整合データをスキャンして修復を試みます（開発者向け機能）。

### HARD RESET DB (※要注意)
**【危険】** データベースの場所データを全て削除し、初期シードデータで上書きリセットします。
- 開発中にデータが乱れすぎて初期状態に戻したい場合のみ使用してください。

### DELETE MY LOGS (※要注意)
ログイン中のユーザーの全ダイビングログを削除します。ログのインポートテスト等をやり直したい場合に使用します。
---

## 5. AIデータクレンジング & 生物マッピング

AIを活用して、ダイビングポイントと生物の紐付け（生息・出現情報）を自動検証・管理するシステムです。

### 5.1 Dashboard (実行設定)
クレンジングジョブの条件を設定し、実行を開始する画面です。

#### 統計情報の確認 (Stats)
- **TOTAL MAPPINGS**: システムに登録されている「ポイント」と「生物」の紐付け（生息・出現記録）の総数です。承認済み（Active）とAI提案の保留中（Pending）の両方の合計値が表示されます。
- **POINTS / CREATURES**: それぞれ、マスタに登録されているダイビングポイント数と生物の種類の総数です。

#### 実行モードの設定 (Execution Mode)
- **新規 (New)**: 紐付けが一件もないポイント・生物のペアのみをスキャンします。初回構築時や、マスタ追加後の差分更新に使用します。
- **リセット (All)**: 既存の全紐付けを一度無視して、全マスタを対象に再判定・再構成します。全体的な整合性を整えるのに適していますが、実行時間が最も長くなります。
- **範囲指定 (Specific)**: 特定のポイントまたは生物に絞って実行します。指定した対象のみを素早く検証したい場合に便利です。
- **入れ替え (Replace)**: 特定のペアに対し、既存の紐付けを削除してからAIに再判定させます。既存の誤判定をピンポイントで修正したい場合に有効です。

#### ターゲット選択 (Target Selection)
Modeが `Specific` または `Replace` の場合に設定可能です。大規模な一括クレンジングからピンポイントの修正まで柔軟に対応しています。

- **階層フィルタ (Hierarchy)**: 「地域 (Region) > エリア (Zone) > 詳細エリア (Area)」の順で絞り込みが可能です。
  - **一括選択**: 下位の項目を「全選択（All）」状態にすることで、その括り全体を対象にクレンジングを実行できます。
    - 例：Regionで「沖縄」を選択し、下位を空にすると、沖縄県内の全ポイントが対象になります。
- **検索フィルタ (Search)**:
  - **ポイント検索**: ポイント名やエリア名でターゲットを高速に検索できます。
  - **生物検索**: 種類名、科名、学名で検索して対象生物を指定できます。
- **ポイント選択 (Point)**: 最終的なターゲットとなるポイントを選択します。空欄の場合は、上記で指定したエリア全体の全ポイントが対象になります。
- **Target Creature**: (任意) 特定の生物1種類に絞りたい場合に活用してください。指定しない場合は、そのポイント（またはエリア）の全候補生物が自動的に検証対象となります。

#### 実行ボタン (Run Action)
- **クレンジング実行開始**: 設定した条件で AI パイプラインを起動します。
  - **確認ダイアログ**: 実行前に「どの範囲（特定ポイントか、エリア全体か）」が対象になるかの確認メッセージが表示されます。必ず内容を確認してから開始してください。
  - **バックグラウンド実行 (v2.1.5〜)**: 実行ボタンを押すと、処理は Google Cloud のバックグラウンドジョブ（Cloud Run Jobs）として即座に切り離されます。
  - **タイムアウトなし**: ブラウザを閉じてしまっても処理は継続されます。数千件規模のエリア一括処理も、タイムアウトを気にせず実行可能です。
  - **ステータスの確認**: 処理結果は順次 `point_creatures` に反映され、レビューエンジン（5.2）から確認できるようになります。詳細な進行状況やエラーログを確認したい場合は、Google Cloud Console の [Cloud Run] > [Jobs] を確認してください。

---

### 5.2 Review Engine (レビュー・承認)
AIが生成した提案（`pending` 状態のデータ）を人間が精査し、本番環境へ反映させる画面です。
※バッチ処理で生成されたデータは `method: "python-batch-v1"` という識別子が付きます。

#### 表示切り替え
- **By Point (ポイント別)**: 左側にポイントリストが表示され、選択するとその地点に生息可能な生物の提案が右側に並びます。特定のポイントの生物相を整えるのに適しています。
- **By Creature (生物別)**: 左側に生物リストが表示され、選択するとその生物が目撃される可能性のあるポイントが右側に並びます。特定の生物（例: マンタ）の出現ポイントを一括確認するのに適しています。

#### 提案データの表示項目
- **信頼度スコア (Confidence)**: AIがその判定にどれだけ自信を持っているかを 0.0〜1.0 で表します。
  - `0.8以上`: 物理的確証＋目撃実績あり。信頼性が非常に高い。
  - `0.5〜0.7`: 生息可能だが目撃実績が薄い。詳細な確認を推奨。
- **レアリティ (Local Rarity)**: そのポイントでの珍しさを 4 段階（Common, Rare, Epic, Legendary）で表示します。
- **Reasoning (根拠・証拠)**: AIが判定の根拠とした生態情報や、Google検索で見つけた目撃実績のサマリー（出典付き）が表示されます。

#### アクション (Actions)
- **Approve (承認)**: アイコン `Check`。提案を確定させ、`status: active` として本番のダイビングポイント詳細画面に表示されるようにします。
- **Reject (却下)**: アイコン `X`。提案が間違っていると判断し、データを物理削除します。
- **一括承認/却下 (Bulk Actions)**: 複数のチェックボックスを選択して、画面下部のアクションバーから一括処理が可能です。大量の `pending` データを整理する際に使用します。

---

### 5.3 技術仕様 (Technical Specifications)

本システムは、膨大な生物マスタとダイビングポイントを効率的かつ正確に紐付けるため、以下の 2 段階の AI 処理プロセス（パイプライン）を採用しています。

#### A. 2 段階の判定プロセス (The 2-Stage Pipeline) - v2.1.5 強化版

1.  **Stage 1: 物理的生存・分布判定 (Batch Potential Check + Context Caching)**
    *   **入力**: ポイントの基本情報（最大水深、地形、地域）＋ 全生物マスタ（キャッシュ済み）。
    *   **処理**: AI が提供された生物辞書を高速にスキャンし、「この水深でこの地形なら、この生物は生息し得るか？」を一次判定します。
    *   **コスト最適化**: **Context Cache** により入力トークンを最小化。また、処理中にキャッシュが期限切れ（TTL切れ）を起こしても、自動的に再生成して続行する **Self-Healing 機能** を搭載しています。
2.  **Stage 2: 事実確認・目撃実績の精査 (Grounding with Google Search)**
    *   **入力**: Stage 1 で「生息可能」と判定されたペア。
    *   **高速化ロジック (v2.1.5)**: Stage 1 での **確信度が 0.85 以上**（きわめて確実）な場合は、 Stage 2 の Google 検索をスキップして即時保存します。これにより判定時間を大幅に短縮しつつコストを削減します。
    *   **処理**: 確信度が中程度の場合のみ、**Google Search Tool** で Web 上の目撃記録をリアルタイムに検索します。

#### B. 内部判定スコアリング (v2.1.5)

*   **信頼度 (Confidence)** の算出：
    *   Stage 1 確信度と Stage 2 の実在確認結果を統合して算出。
    *   `0.85以上`: AIが自信を持って「いる」と判断。Stage 2 スキップ対象。
    *   `0.8以上（ rejected 判断時 ）`: Stage 2 でWeb証拠が見つからなくても、Stage 1 の確信度が高ければ `pending` として残し、管理者の判断を仰ぎます。
    *   これにより、「Web に記録はないが生態的に生息可能（高スコア）」と「実際に目撃例が多数（最高スコア）」を区別しています。

---

### 5.4 実行シナリオと引数 (Execution Scenarios)

コマンドライン、または管理画面から渡される引数に応じた内部動作の詳細は以下の通りです。

| 引数名 | 想定される値 | 内部動作の仕組み |
| :--- | :--- | :--- |
| **`--mode`** | `new` | **[シナリオ：差分更新]** Firestore の `point_creatures` に存在しないペアのみを新規作成します。既存データは一切上書き・参照しません。コストが最も低いです。 |
| | `all` | **[シナリオ：全体再構築]** 指定された全ポイントを対象にスキャンし、既存データがあっても最新の AI 判定結果で上書きします。 |
| | `specific` | **[シナリオ：範囲指定]** `--region` や `--pointId` 等のフィルタで絞り込まれた範囲に対してのみ実行します。 |
| | `replace` | **[シナリオ：修正・入替]** `specific` と同様ですが、既存データを明示的に上書きする意図で、特定のポイントや生物をピンポイントで再判定します。 |
| **`--pointId`** | (ドキュメントID) | 特定の 1 ポイントのみを対象にします。 |
| **`--creatureId`** | (ドキュメントID) | 特定の 1 生物のみを対象にします。プロンプトでもこの生物を重点的に探すようフォーカスが掛かります。 |
| **`--region`** | (名称) | 指定された Region（例：沖縄本島）に属する全ポイントをリストアップして処理します。 |
| **`--limit`** | 100 等の数値 | 1 回のジョブで処理する最大のポイント数を制限します。テスト実行時や、一日の API クォータを守るために使用します。 |

---

### 5.5 運用上のヒント
- **コスト効率 (Context Caching)**: v2.1.5 より、大規模なジョブ実行時は生物辞書のキャッシュ機能を活用します。全件実行（All）のトークンコストが従来比で約 75% 削減されています。
- **まずは Specific で試す**: 全件実行する前に、よく知っているポイントに対して `Specific` モードで実行し、スコアや根拠が妥当か確認することをお勧めします。
- **Pending データの放置**: `pending` 状態のデータは一般ユーザーには一切見えません。信頼度が低いものは `pending` のまま保留にせず、積極的に却下または修正を行ってください。
- **バックアップ**: 大規模なクレンジングや承認を行う前には、`Export Relations` ボタンで現状の紐付けデータをダウンロードしておくことを強く推奨します。
- **リージョン固定 (Technical)**: 最新モデル（Gemini 2.0 Flash）とキャッシュ機能を安定利用するため、AI の処理リージョンは自動的に `us-central1` に固定されています。Firestore への保存先には影響しません。
