import os
import json
import time
import argparse
import google.generativeai as genai

# --- è¨­å®š ---
API_KEY = os.environ.get("GOOGLE_API_KEY", "YOUR_API_KEY_HERE")
INPUT_FILE = "src/data/locations_structure.json" # éª¨çµ„ã¿ï¼ˆãƒã‚¹ã‚¿ï¼‰
OUTPUT_FILE = "src/data/locations_seed.json"     # ä½œæ¥­çµæœï¼ˆãƒã‚¤ãƒ³ãƒˆå…¥ã‚Šï¼‰

# ãƒã‚¤ãƒ³ãƒˆç”Ÿæˆã®å®šç¾©
POINT_SCHEMA = """
Output JSON Array of Objects:
[
  {
    "name": "Point Name",
    "level": "Beginner / Intermediate / Advanced",
    "maxDepth": int,
    "entryType": "boat / beach",
    "current": "none / weak / strong / drift",
    "topography": ["cave", "dropoff", "sand", "rock"],
    "features": ["manta", "shark", "macro", "wreck"],
    "description": "Short description about 100 chars.",
    "imageKeyword": "english keyword"
  }
]
"""

def generate_points_for_area(region: str, zone: str, area: str, count: int) -> list:
    """ç‰¹å®šã‚¨ãƒªã‚¢å†…ã®ãƒã‚¤ãƒ³ãƒˆãƒªã‚¹ãƒˆã‚’ç”Ÿæˆã™ã‚‹"""
    print(f"  generating {count} points for: {area} ({region}/{zone})...", end="", flush=True)

    genai.configure(api_key=API_KEY)
    model = genai.GenerativeModel('gemini-2.0-flash')

    prompt = f"""
    ãƒ€ã‚¤ãƒ“ãƒ³ã‚°ã‚¨ãƒªã‚¢: {region} > {zone} > {area}
    ã“ã®ã‚¨ãƒªã‚¢ï¼ˆ{area}ï¼‰ã«ã‚ã‚‹äººæ°—ã®ãƒ€ã‚¤ãƒ“ãƒ³ã‚°ãƒã‚¤ãƒ³ãƒˆã‚’ã€ {count}ç®‡æ‰€ ã€‘ãƒªã‚¹ãƒˆã‚¢ãƒƒãƒ—ã—ã¦ãã ã•ã„ã€‚

    æ¡ä»¶:
    1. å®Ÿåœ¨ã™ã‚‹ãƒã‚¤ãƒ³ãƒˆåã‚’ä½¿ç”¨ã™ã‚‹ã“ã¨ã€‚
    2. æ°´æ·±ã‚„ãƒ¬ãƒ™ãƒ«ã¯ãƒªã‚¢ãƒ«ãªãƒ‡ãƒ¼ã‚¿ã‚’å…¥ã‚Œã‚‹ã“ã¨ã€‚
    3. JSONé…åˆ—ã®ã¿ã‚’å‡ºåŠ›ã™ã‚‹ã“ã¨ã€‚

    {POINT_SCHEMA}
    """

    try:
        response = model.generate_content(prompt)
        text = response.text.strip()
        if text.startswith("```json"): text = text[7:]
        if text.startswith("```"): text = text[3:]
        if text.endswith("```"): text = text[:-3]
        if text.strip().endswith("}"): text += "]"

        points = json.loads(text)
        print(f" âœ… Got {len(points)} points.")
        return points
    except Exception as e:
        print(f" âŒ Error: {e}")
        return []

def deep_merge_regions(existing_data: list, structure_data: list) -> list:
    """
    æ—¢å­˜ãƒ‡ãƒ¼ã‚¿(existing_data)ã«å¯¾ã—ã¦ã€æ§‹é€ ãƒ‡ãƒ¼ã‚¿(structure_data)ã‚’ãƒãƒ¼ã‚¸ã™ã‚‹ã€‚
    Region -> Zone -> Area ã®éšå±¤ã‚’ä¸‹ã‚ŠãªãŒã‚‰ã€æ–°ã—ã„è¦ç´ ãŒã‚ã‚Œã°è¿½åŠ ã™ã‚‹ã€‚
    æ—¢å­˜ã®ãƒã‚¤ãƒ³ãƒˆãƒ‡ãƒ¼ã‚¿ãªã©ã¯ä¿æŒã™ã‚‹ã€‚
    """
    merged_map = {r["id"]: r for r in existing_data if "id" in r}

    for struct_region in structure_data:
        r_id = struct_region.get("id")

        if r_id not in merged_map:
            # æ–°ã—ã„Regionãªã‚‰ãã®ã¾ã¾è¿½åŠ 
            print(f"  -> New region detected: {struct_region.get('name')}")
            merged_map[r_id] = struct_region
            continue

        # æ—¢å­˜RegionãŒã‚ã‚‹å ´åˆã€Zoneãƒ¬ãƒ™ãƒ«ã§ãƒãƒ¼ã‚¸
        existing_region = merged_map[r_id]
        existing_zones = existing_region.get("children", [])
        struct_zones = struct_region.get("children", [])

        # Zone ID map
        existing_zone_map = {z["id"]: z for z in existing_zones if "id" in z}

        for struct_zone in struct_zones:
            z_id = struct_zone.get("id")

            if z_id not in existing_zone_map:
                # æ–°ã—ã„Zoneãªã‚‰è¿½åŠ 
                print(f"    -> New zone detected: {struct_zone.get('name')}")
                existing_zones.append(struct_zone)
                existing_zone_map[z_id] = struct_zone # Update map for subsequent lookups if needed
                continue

            # æ—¢å­˜ZoneãŒã‚ã‚‹å ´åˆã€Areaãƒ¬ãƒ™ãƒ«ã§ãƒãƒ¼ã‚¸
            existing_zone = existing_zone_map[z_id]
            existing_areas = existing_zone.get("children", [])
            struct_areas = struct_zone.get("children", [])

            # Area ID map
            existing_area_map = {a["id"]: a for a in existing_areas if "id" in a}

            for struct_area in struct_areas:
                a_id = struct_area.get("id")

                if a_id not in existing_area_map:
                    # æ–°ã—ã„Areaãªã‚‰è¿½åŠ 
                    print(f"      -> New area detected: {struct_area.get('name')}")
                    existing_areas.append(struct_area)
                    existing_area_map[a_id] = struct_area
                else:
                    # Areaã‚‚æ—¢ã«å­˜åœ¨ã™ã‚‹ãªã‚‰ä½•ã‚‚ã—ãªã„ï¼ˆãƒã‚¤ãƒ³ãƒˆãƒ‡ãƒ¼ã‚¿ã¯æ—¢å­˜ã‚’å„ªå…ˆï¼‰
                    pass

            existing_zone["children"] = existing_areas

        existing_region["children"] = existing_zones
        merged_map[r_id] = existing_region

    return list(merged_map.values())

def load_and_sync_data():
    """
    Structure(éª¨çµ„ã¿)ã¨Seed(æ—¢å­˜ãƒ‡ãƒ¼ã‚¿)ã‚’åŒæœŸãƒ­ãƒ¼ãƒ‰ã™ã‚‹é‡è¦ãªé–¢æ•°
    æ–°ã—ã„Region/Zone/AreaãŒStructureã«è¿½åŠ ã•ã‚Œã¦ã„ãŸã‚‰ã€Seedã«ã‚‚å–ã‚Šè¾¼ã‚€
    """
    if not os.path.exists(INPUT_FILE):
        print(f"âŒ Input file {INPUT_FILE} not found. Run generate_structure.py first.")
        return []

    # 1. éª¨çµ„ã¿ï¼ˆæœ€æ–°ã®å…¨ã‚¨ãƒªã‚¢æ§‹é€ ï¼‰
    with open(INPUT_FILE, 'r', encoding='utf-8') as f:
        structure_data = json.load(f)

    # 2. æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ï¼ˆãƒã‚¤ãƒ³ãƒˆå–å¾—æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ï¼‰ãŒãªã„å ´åˆã¯éª¨çµ„ã¿ã‚’ãã®ã¾ã¾è¿”ã™
    if not os.path.exists(OUTPUT_FILE):
        return structure_data

    # 3. æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚‹å ´åˆã¯ãƒãƒ¼ã‚¸å‡¦ç†
    print(f"ğŸ“‚ Syncing structure from {INPUT_FILE} into {OUTPUT_FILE}...")
    try:
        with open(OUTPUT_FILE, 'r', encoding='utf-8') as f:
            existing_data = json.load(f)
    except json.JSONDecodeError:
        # æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ãŒå£Šã‚Œã¦ã„ã‚‹å ´åˆã¯éª¨çµ„ã¿ã‚’æ­£ã¨ã™ã‚‹
        return structure_data

    # Deep Mergeã‚’å®Ÿè¡Œ
    merged_data = deep_merge_regions(existing_data, structure_data)

    return merged_data

def main():
    parser = argparse.ArgumentParser()
    parser.add_argument("--id", type=str, help="Target Area ID")
    parser.add_argument("--count", type=int, default=5, help="Number of points")
    args = parser.parse_args()

    target_area_id = args.id
    target_count = args.count

    # â˜…ã“ã“ã§åŒæœŸãƒ­ãƒ¼ãƒ‰ã‚’å®Ÿè¡Œ
    final_data = load_and_sync_data()
    if not final_data:
        return

    processed_areas = 0
    target_found = False

    print(f"ğŸš€ Starting point generation... (Target ID: {target_area_id if target_area_id else 'ALL'})")

    # Region Loop
    for region in final_data:
        region_name = region.get("name")

        if "children" in region:
            for zone in region["children"]:
                zone_name = zone.get("name")

                if "children" in zone:
                    for area in zone["children"]:
                        area_name = area.get("name")
                        area_id = area.get("id")

                        # ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
                        if target_area_id and area_id != target_area_id:
                            continue

                        target_found = True

                        # å…¨è‡ªå‹•ãƒ¢ãƒ¼ãƒ‰ã‹ã¤ãƒ‡ãƒ¼ã‚¿å–å¾—æ¸ˆã¿ãªã‚‰ã‚¹ã‚­ãƒƒãƒ—
                        existing_points = area.get("children", [])
                        if not target_area_id:
                            if existing_points and len(existing_points) > 0 and existing_points[0].get("type") == "Point":
                                continue

                        # ç”Ÿæˆå®Ÿè¡Œ
                        points_data = generate_points_for_area(region_name, zone_name, area_name, target_count)

                        if points_data:
                            formatted_points = []
                            base_id = area_id if area_id else f"tmp_{time.time()}"

                            for p_i, p in enumerate(points_data):
                                p["id"] = f"p_{base_id}_{p_i}"
                                p["type"] = "Point"
                                keyword = p.get("imageKeyword", "diving").replace(" ", "")
                                p["image"] = f"[https://loremflickr.com/400/300/](https://loremflickr.com/400/300/){keyword},underwater"
                                formatted_points.append(p)

                            area["children"] = formatted_points
                            processed_areas += 1

                            # ä¿å­˜
                            with open(OUTPUT_FILE, 'w', encoding='utf-8') as f:
                                json.dump(final_data, f, indent=2, ensure_ascii=False)
                            print("  ğŸ’¾ Saved.")

                        if target_area_id:
                            print(f"\nâœ¨ Target area '{area_name}' processed.")
                            return

                        time.sleep(2)

    if target_area_id and not target_found:
        print(f"\nâš ï¸ Warning: Area ID '{target_area_id}' not found.")
    else:
        print(f"\nâœ¨ Done! Processed {processed_areas} areas.")

if __name__ == "__main__":
    main()
