import os
import json
import time
import google.generativeai as genai
import argparse
import shutil
from typing import List, Dict

# --- è¨­å®š ---
# API Key
API_KEYS = os.environ.get("GOOGLE_API_KEY", "").split(",")
if not API_KEYS or not API_KEYS[0]:
    raise ValueError("GOOGLE_API_KEY environment variable is not set.")

BASE_DIR = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
CONFIG_DIR = os.path.join(BASE_DIR, "scripts/config")
DATA_DIR = os.path.join(BASE_DIR, "src/data")
INPUT_FILE = os.path.join(CONFIG_DIR, "target_zones.json")
OUTPUT_FILE = os.path.join(DATA_DIR, "locations_seed.json")
PRODUCED_AREAS_FILE = os.path.join(CONFIG_DIR, "target_areas.json")

# Models to cycle through
CANDIDATE_MODELS = [
    'gemini-2.5-flash',
    'gemini-2.5-flash-lite',
    'gemma-3-27b-it',
    'gemma-3-12b-it',
    'gemma-3-4b-it',
    'gemma-3-2b-it',
    'gemma-3-1b-it',
]

# Flattened Resource Pool: [(model, key), (model, key)...]
RESOURCE_POOL = [(m, k) for m in CANDIDATE_MODELS for k in API_KEYS]
current_resource_index = 0

def get_current_resource():
    return RESOURCE_POOL[current_resource_index]

def rotate_resource():
    global current_resource_index
    current_resource_index = (current_resource_index + 1) % len(RESOURCE_POOL)
    print(f"    ğŸ”„ Switching to Resource #{current_resource_index + 1}/{len(RESOURCE_POOL)}")

def generate_areas(region: str, zone: str) -> List[Dict]:
    global current_resource_index

    prompt = f"""
    ã‚ãªãŸã¯ãƒ™ãƒ†ãƒ©ãƒ³ã®ãƒ€ã‚¤ãƒ“ãƒ³ã‚°ã‚¬ã‚¤ãƒ‰ã§ã™ã€‚
    æŒ‡å®šã•ã‚ŒãŸã€ŒZoneï¼ˆåœ°åŸŸï¼‰ã€ã«å«ã¾ã‚Œã‚‹ã€å…·ä½“çš„ãªã€ŒAreaï¼ˆãƒ€ã‚¤ãƒ“ãƒ³ã‚°ã‚¹ãƒãƒƒãƒˆã®é›†ã¾ã‚Šï¼‰ã€ã‚’ãƒªã‚¹ãƒˆã‚¢ãƒƒãƒ—ã—ã¦ãã ã•ã„ã€‚

    Region: {region}
    Zone: {zone}

    å‡ºåŠ›ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆï¼ˆJSONï¼‰:
    [
      {{
        "name": "Areaåï¼ˆä¾‹: å˜‰æ¯”å³¶, ãƒãƒ³ã‚¿ã‚¹ã‚¯ãƒ©ãƒ³ãƒ–ãƒ«å‘¨è¾ºï¼‰",
        "description": "ãã®ã‚¨ãƒªã‚¢ã®ãƒ€ã‚¤ãƒ“ãƒ³ã‚°ã®ç‰¹å¾´ã‚’100æ–‡å­—ä»¥å†…ã§"
      }}
    ]

    æ³¨æ„ç‚¹:
    - Zoneã‚’ã•ã‚‰ã«ç´°åˆ†åŒ–ã—ãŸã‚¨ãƒªã‚¢ã§ã™ã€‚
    - 3ã€œ5å€‹ç¨‹åº¦æŒ™ã’ã¦ãã ã•ã„ã€‚
    - ã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯ã¯å«ã‚ãªã„ã§ãã ã•ã„ã€‚
    """

    max_attempts = len(RESOURCE_POOL)
    attempts = 0

    while attempts < max_attempts:
        model_name, api_key = get_current_resource()

        try:
            genai.configure(api_key=api_key)
            model = genai.GenerativeModel(model_name)

            response = model.generate_content(prompt)
            text = response.text.strip()
            # Remove markdown if present
            if text.startswith("```json"):
                text = text[7:]
            if text.endswith("```"):
                text = text[:-3]

            result = json.loads(text)
            if result:
                # Success! Keep the current index as is (it's working).
                # Identify which key index this matches for display (just for info)
                key_display_idx = API_KEYS.index(api_key) + 1
                print(f"    âœ… Success with {model_name} (Key #{key_display_idx})")
                return result

        except Exception as e:
            error_str = str(e)
            if "429" in error_str:
                print(f"    âš ï¸ Quota exceeded: {model_name} (Key index in pool: {current_resource_index})")
                rotate_resource()
                time.sleep(1)
            elif "404" in error_str or "not found" in error_str.lower():
                print(f"    â„¹ï¸ Model {model_name} not found/supported. Skipping.")
                rotate_resource()
            else:
                print(f"    âŒ Error with {model_name}: {e}")
                rotate_resource()

        attempts += 1

    print(f"    ğŸ’€ All models failed for {zone}")
    return []

import argparse
import shutil

def main():
    parser = argparse.ArgumentParser(description="Generate Areas data.")
    parser.add_argument("--mode", choices=["append", "overwrite", "clean"], default="append",
                        help="Execution mode: append (skip existing), overwrite (replace existing), clean (start fresh)")
    args = parser.parse_args()

    if not os.path.exists(INPUT_FILE):
        print(f"âŒ Config file not found: {INPUT_FILE}")
        return

    with open(INPUT_FILE, 'r', encoding='utf-8') as f:
        target_zones = json.load(f)

    all_locations = []

    # Mode: Clean -> Backup and reset
    if args.mode == "clean":
        if os.path.exists(OUTPUT_FILE):
            shutil.copy(OUTPUT_FILE, OUTPUT_FILE + ".bak")
            print(f"ğŸ“¦ Backed up existing file to {OUTPUT_FILE}.bak")
        all_locations = []
    # Mode: Append / Overwrite -> Load existing
    elif os.path.exists(OUTPUT_FILE):
        with open(OUTPUT_FILE, 'r', encoding='utf-8') as f:
            try:
                all_locations = json.load(f)
            except:
                pass

    produced_areas_list = []
    print(f"ğŸš€ Generating Areas for {len(target_zones)} zones... [Mode: {args.mode.upper()}]")

    for target in target_zones:
        region_name = target["region"]
        zone_name = target["zone"]
        print(f"  Processing {region_name} > {zone_name}...")

        # Region/Zone Nodeæ¤œç´¢
        region_node = next((r for r in all_locations if r["name"] == region_name), None)
        if not region_node:
            print(f"    âš ï¸ Region {region_name} not found. Skipping.")
            continue

        zone_node = next((z for z in region_node.get("children", []) if z["name"] == zone_name), None)
        if not zone_node:
            print(f"    âš ï¸ Zone {zone_name} not found. Skipping.")
            continue

        existing_areas = zone_node.get("children", [])

        # Mode: Append - Check if areas already exist
        if args.mode == "append" and len(existing_areas) > 0:
            print(f"    â­ï¸  Skipping (Areas already exist).")
            # Next Stepç”¨ã«è¨˜éŒ²
            for a in existing_areas:
                produced_areas_list.append({"region": region_name, "zone": zone_name, "area": a["name"]})
            continue

        # Mode: Overwrite - Clear existing areas
        if args.mode == "overwrite" and len(existing_areas) > 0:
            print(f"    â™»ï¸  Overwriting areas...")
            existing_areas = []

        # Generate
        new_areas = generate_areas(region_name, zone_name)

        # Merge (Overwriteã®å ´åˆã¯ç©ºé…åˆ—ã¸ã®è¿½åŠ ã«ãªã‚‹ã®ã§å®Ÿè³ªæ–°è¦)
        existing_area_names = {a["name"] for a in existing_areas}

        for i, new_a in enumerate(new_areas):
            if new_a["name"] not in existing_area_names:
                new_a["id"] = f"a_{int(time.time())}_{new_a['name']}"
                existing_areas.append(new_a)
                print(f"    + Added Area: {new_a['name']}")
                produced_areas_list.append({"region": region_name, "zone": zone_name, "area": new_a["name"]})
            else:
                # æ—¢ã«ã‚ã‚‹å ´åˆã¯ã€æ—¢å­˜ã®IDãªã©ã‚’ç¶­æŒã—ãŸã„ã‹ã€ä¸Šæ›¸ãã—ãŸã„ã‹ã€‚
                # ã“ã“ã§ã¯å˜ç´”ã«ã‚¹ã‚­ãƒƒãƒ—ã—ã¤ã¤ã€NextStepãƒªã‚¹ãƒˆã«ã¯å…¥ã‚Œã‚‹
                print(f"    . Exists: {new_a['name']}")
                produced_areas_list.append({"region": region_name, "zone": zone_name, "area": new_a["name"]})

        zone_node["children"] = existing_areas

        # Save Main Data Incrementally
        os.makedirs(DATA_DIR, exist_ok=True)
        with open(OUTPUT_FILE, 'w', encoding='utf-8') as f:
            json.dump(all_locations, f, indent=2, ensure_ascii=False)
        print(f"    ğŸ’¾ Progress saved to {OUTPUT_FILE}")

        time.sleep(2)

    # Save Config for Next Step (Final)
    with open(PRODUCED_AREAS_FILE, 'w', encoding='utf-8') as f:
        json.dump(produced_areas_list, f, indent=2, ensure_ascii=False)

    print(f"\nâœ… All Done!")
    print(f"ğŸ“ Generated next step config: {PRODUCED_AREAS_FILE}")

if __name__ == "__main__":
    main()
