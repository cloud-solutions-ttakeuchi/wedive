# Issue: Firestore 読み取りコストの最適化と高速なマスタデータ配信基盤の構築

## 1. 現状の課題 (Current Issues)
### 1.1 Firestore Read コストの増大リスク
現在のモバイルアプリ（wedive-app）の一部の実装において、マスタデータ（ポイント一覧、生物一覧）を Firestore から全件同期（Snapshot受信）しようとするロジックが存在する。
- **リスク**: データ件数が数千件を超え、ユーザー数が増加した場合、1ユーザーのアクセスごとに膨大な Read クエリが発生し、インフラ費用が指数関数的に増大する（破産リスク）。
- **具体例**: 1万件のマスタデータを1万人が参照すると、1億回の Read が発生。

### 1.2 アプリケーションのパフォーマンス劣化（無限ローディング）
全件取得が完了するまで画面表示をブロックする実装により、ネットワーク環境やデータ量に応じて「読み込みが終わらない」現象が発生している。
- **現状**: ログ編集画面（EditLogScreen）等で顕著に発生。

## 2. 解決案 (Proposed Solutions)

### 2.1 【短期】案1: オンデマンド取得への切り替え (On-demand Fetching)
アプリ内のマスタデータ参照を「全件ロード」から「必要な時だけ取得」に変更する。
- **実装**: `PointSelectorModal`, `CreatureSelectorModal` 等を利用し、ユーザーが検索キーワードを入力したタイミングで `limit(20)` 程度の制限付きで Firestore に問い合わせる。
- **効果**: Read コストを 99% 以上削減し、即座に画面を表示可能にする。

### 2.2 【中期】案2: GCS Mirror Architecture via BigQuery Data Factory
マスタデータの配信元を Firestore から、より安価で高速な静的配信（GCS）へ移行し、BigQuery を「データ加工エンジン」として活用する。
- **アーキテクチャ**:
  1. **Source**: Firestore (マスターデータ)
  2. **Sync**: Firebase Extension「Stream Firestore to BigQuery」を使用し、ニアリアルタイムで BigQuery へ同期。
  3. **ETL (BigQuery)**: 検索に必要なフィールド（名称、カナ、地域など）のみを抽出し、データサイズを極限まで軽量化した「配信専用テーブル」を SQL で作成。
  4. **Export**: BigQuery から **GCS (Cloud Storage)** へ JSON 形式で定期エクスポート（1〜数時間に1回）。
  5. **Client (App)**: 
     - アプリ起動時、または検索画面表示時に GCS から最新の JSON を 1 回だけ DL（数MB以下）。
     - **検索処理**: 通信を完全に排し、ダウンロードした JSON に対して「ローカル・インメモリ検索」を実行。
- **効果**:
  - **コスト**: Firestore の Read 課金を 0 に抑制。BigQuery のクエリ課金もバッチ処理の 1 回分のみ（ほぼ無料枠）。
  - **体験**: BigQuery のレイテンシ（数秒）を完全に隠蔽し、ユーザーへは 0.1秒以下の爆速検索を提供。
  - **スケーラビリティ**: ユーザー数が数万人になっても、配信元は静的ファイルサーバーなので性能劣化しない。

## 3. ロードマップ (Roadmap)
1. **Phase 1 (即時)**: `EditLogScreen` の全件ロード処理を撤廃し、オンデマンド取得へリファクタリング（バグ解消）。
2. **Phase 2 (設計)**: GCP Cloud Functions / Workflows を用いた Firestore → GCS → BigQuery のエクスポートパイプラインの構築。
3. **Phase 3 (移行)**: アプリの各マスタデータフェッチを GCS 経由に切り替え。

---
## 4. 完了定義 (Definition of Done)
- [ ] アプリの初期表示からマスタデータの全件待ちを排除する。
- [ ] 検索時の Read 回数が `limit` 値以下であることを確認する。
- [ ] GCS 経由でのマスタ配信パスを確立する。
